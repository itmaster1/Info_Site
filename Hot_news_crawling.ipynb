{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hot_news_crawling",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "107vi69lP9kR0uyBFiDlQhRq0SpKu41HX",
      "authorship_tag": "ABX9TyPP6YgRQ70sIH6IuRULK5JI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itmaster1/Info_Site/blob/master/Hot_news_crawling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLx_yAp6PgYM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv7WS28oBIZE"
      },
      "source": [
        "import requests\n",
        "from pandas import DataFrame\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from datetime import datetime\n",
        "import os\n",
        "import pandas\n",
        "\n",
        "date = str(datetime.now())\n",
        "date = date[:date.rfind(':')].replace(' ', '_')\n",
        "date = date.replace(':','시') + '분'\n",
        "\n",
        "\n",
        "dt_index = pandas.date_range(start='20211026', end='20211027')\n",
        "# pandas.date_range(start='20160901', end='20161031',freq='W-MON')\n",
        "# 을 하면 해당 기간 매주 월요일들만 추출합니다.\n",
        "dt_list = dt_index.strftime(\"%Y%m%d\").tolist()\n",
        "\n",
        "news_dict = {}\n",
        "idx = 0\n",
        "cur_page = 0\n",
        "\n",
        "for d in dt_list:\n",
        "    url = 'https://finance.naver.com/news/news_list.naver?mode=RANK&date={}'.format(d)\n",
        "    print(url)\n",
        "    req = requests.get(url) # 가장많인 본 뉴스의 최근일자 일경우 ( 레벨이 5단계가 아닌경우 에러발생 )\n",
        "    soup = BeautifulSoup(req.text, 'html.parser')\n",
        "\n",
        "    page = 0 #일자별 page 초기화 \n",
        "    # 마지막 페이지 숫자 가져오기 \n",
        "    el_table_navi = soup.find(\"table\", class_=\"Nnavi\")\n",
        "    el_td_last = el_table_navi.find(\"td\", class_=\"pgRR\")\n",
        "    pg_last = el_td_last.a.get('href').rsplit('page')[1]\n",
        "    pg_last = pg_last.split('=')[1]\n",
        "    page = int(pg_last)\n",
        "\n",
        "    print()\n",
        "    print('크롤링 중...')\n",
        "\n",
        "    for i in range(1,page+1):\n",
        "        print(i)    \n",
        "        url_1 = url+\"&page=\"+format(i)\n",
        "        #print(url_1)\n",
        "        #req_1 = requests.get('https://finance.naver.com/news/news_list.naver?mode=RANK&date=&date='+str(d) +'&page=&p=' + str(i))\n",
        "        req_1 = requests.get(url_1)\n",
        "        #req_1 = requests.get('https://finance.naver.com/news/news_list.naver?mode=RANK&date=20211026&page=2')\n",
        "        soup = BeautifulSoup(req_1.text, 'html.parser')\n",
        "\n",
        "        #for href in soup.find(\"ul\", class_=\"newsList\").find_all(\"li\"): #newsList\n",
        "        for href in soup.find(\"div\", class_=\"hotNewsList\").find_all(\"li\"):\n",
        "            #news_dict[idx] = href.find(\"a\")[\"title\"]\n",
        "            #print(href)\n",
        "            news_dict[idx] = {'seq' : idx+1\n",
        "                            ,'date': re.sub(r'[^0-9]' , '',str(href.find(\"span\",{'class' : 'wdate'}))), \n",
        "                            'title' : href.find(\"a\")[\"title\"],\n",
        "                            'url' : href.find(\"a\")[\"href\"], # https://finance.naver.com + 해야함                         \n",
        "                            'source': re.sub('[a-zA-Z\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"\\♥\\♡\\ㅋ\\ㅠ\\ㅜ\\ㄱ\\ㅎ\\ㄲ\\ㅡ]' , '',str(href.find(\"span\",{'class' : 'press'})))}\n",
        "            idx += 1\n",
        "\n",
        "print('크롤링 완료')\n",
        "\n",
        "print('데이터프레임 변환')\n",
        "news_df = DataFrame(news_dict).T\n",
        "\n",
        "news_df\n",
        "\n",
        "#mysql 처리 \n",
        "# https://hyun-am-coding.tistory.com/entry/%ED%81%AC%EB%A1%A4%EB%A7%81%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-DB%EC%97%90-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfw_0BFjOf-d"
      },
      "source": [
        "import sqlite3\n",
        "print(sqlite3.version)\n",
        "print(sqlite3.sqlite_version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WG10uf8Ssu_"
      },
      "source": [
        "# DB 생성 (오토 커밋)\n",
        "conn = sqlite3.connect(\"hot_news_data.db\", timeout=10)\n",
        "# 커서 획득\n",
        "c = conn.cursor()\n",
        "\n",
        "# 실행할 때마다 다른값이 나오지 않게 테이블을 제거해두기 \n",
        "c.execute(\"DROP TABLE IF EXISTS news\")\n",
        "\n",
        "# 테이블 생성 (데이터 타입은 TEST, NUMERIC, INTEGER, REAL, BLOB 등)\n",
        "c.execute(\"CREATE TABLE IF NOT EXISTS news \\\n",
        "    (seq int PRIMARY KEY, news_date text  , title text, new_url text, news_source text)\")\n",
        "\n",
        "# 데이터 저장하기\n",
        "for row in news_df.itertuples():\n",
        "    sql = \"insert into news(seq, news_date, title, new_url,news_source) values(?,?,?,?,?)\"\n",
        "    c.execute(sql,(row[1],row[2],row[3],row[4],row[5]))\n",
        "\n",
        "# 커밋하기 \n",
        "conn.commit() \n",
        "# 연결종료하기 \n",
        "conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f8Fk-wsYZlP"
      },
      "source": [
        "# 데이터 조회(전체) \n",
        "# DB 생성 (오토 커밋)\n",
        "conn = sqlite3.connect(\"hot_news_data.db\", timeout=10)\n",
        "# 커서 획득\n",
        "c = conn.cursor()\n",
        "\n",
        "c.execute(\"SELECT * FROM news\")\n",
        "\n",
        "rows = c.fetchall() \n",
        "for row in rows: \n",
        "    print('retrieve1 >', row) # 조회 없음\n",
        "\n",
        "# 커밋하기 \n",
        "conn.commit() \n",
        "# 연결종료하기 \n",
        "conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}